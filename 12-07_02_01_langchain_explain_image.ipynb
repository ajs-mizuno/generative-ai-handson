{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b5d7863",
   "metadata": {},
   "source": [
    "# 画像内容を生成AIに説明させる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7592e494",
   "metadata": {},
   "source": [
    "画像データをRAGで扱う場合に画像内容がどのようなものであるかをテキスト化して登録しておくと検索しやすくなる。  \n",
    "そこで取り扱う画像データ（図表など）を生成AIを活用してどのような内容であるか説明させ、説明文とも画像パスを保存すると  \n",
    "検索時に画像付きの応答を帰すことが可能となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2869ee4c",
   "metadata": {},
   "source": [
    "## 対象の画像ファイルパスを指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ed2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像のパス\n",
    "path=\"data/image.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b01e7ee",
   "metadata": {},
   "source": [
    "## 画像説明処理の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f4008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers \\\n",
    "    import StrOutputParser\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 1. 画像をBase64文字列に変換するRunnable\n",
    "encode_image = RunnableLambda(\n",
    "    lambda path: base64.b64encode(open(path, \"rb\").read()).decode(\"utf-8\"))\n",
    "\n",
    "# 2. ユーザーメッセージを構築するRunnable\n",
    "#    role と content のリストで、テキスト指示＋画像データを渡す\n",
    "user_message = RunnableLambda(\n",
    "    lambda b64: [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"添付画像の内容について解説してください。\"},\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"source_type\": \"base64\",\n",
    "                \"mime_type\": \"image/png\",\n",
    "                \"data\": b64,\n",
    "            },\n",
    "        ]\n",
    "    }])\n",
    "# 3. LLMステップ\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_LLM_DEPLOYMENT_API_VERSION\"),\n",
    "    azure_deployment=os.environ.get(\"AZURE_OPENAI_LLM_DEPLOYMENT_MODEL\")\n",
    ")\n",
    "\n",
    "\n",
    "# 4. テキストとして出力\n",
    "OUTPUT_PARSER = StrOutputParser()\n",
    "\n",
    "# 5. LCELチェーンの定義\n",
    "chain = (\n",
    "    encode_image       # 画像パス → Base64\n",
    "    | user_message     # Base64 → ユーザーメッセージ辞書\n",
    "    | llm              # モデル呼び出し\n",
    "    | OUTPUT_PARSER\n",
    ")\n",
    "\n",
    "# 6. 実行\n",
    "result = chain.invoke(path)\n",
    "\n",
    "# 7. 結果を取得\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
