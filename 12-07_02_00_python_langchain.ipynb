{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "6cc1613b",
            "metadata": {},
            "source": [
                "# LangChainの使い方\n",
                "このノートブックでは、最新の LangChain（v0.3~）を使った各用途別のサンプルを、逐次的に紹介します。"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "99349e2d",
            "metadata": {},
            "source": [
                "## 1. LLM ラッパー\n",
                "OpenAI の API 呼び出しを抽象化したモデルラッパーです。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a135a9b8",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_openai import AzureChatOpenAI\n",
                "import os\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# 環境設定を読込\n",
                "load_dotenv()\n",
                "\n",
                "# 生成AIのチャットモデルを作成\n",
                "llm = AzureChatOpenAI(\n",
                "    azure_deployment=os.environ.get(\"AZURE_OPENAI_LLM_DEPLOYMENT_MODEL\"),\n",
                "    api_version=os.environ.get(\"AZURE_OPENAI_LLM_DEPLOYMENT_API_VERSION\"),\n",
                "    temperature=0.7\n",
                ")\n",
                "\n",
                "# モデル実行\n",
                "print(llm.invoke([{\"role\": \"user\", \"content\": \"こんにちは\"}]).content)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a122bf97",
            "metadata": {},
            "source": [
                "## 2. プロンプトテンプレートとチェイン"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a569e4be",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_openai import AzureChatOpenAI\n",
                "from langchain_core.prompts.chat import PromptTemplate\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "\n",
                "\n",
                "# 1.生成AIモデルを作成\n",
                "llm = AzureChatOpenAI(\n",
                "    azure_deployment=os.environ.get(\"AZURE_OPENAI_LLM_DEPLOYMENT_MODEL\"),\n",
                "    api_version=os.environ.get(\"AZURE_OPENAI_LLM_DEPLOYMENT_API_VERSION\"),\n",
                "    temperature=0.7\n",
                ")\n",
                "\n",
                "# 2.プロンプト雛型を作成\n",
                "# input_variablesにパラメータを定義する\n",
                "# templateに雛型のプロンプトを作成し置換パラメータを埋め込む\n",
                "prompt = PromptTemplate(\n",
                "    input_variables=[\"language\", \"word\"],\n",
                "    template=\"次の単語を{language}語に翻訳してください：{word}\"\n",
                ")\n",
                "\n",
                "# 3.チェインを作成\n",
                "# 指示(Prompt)、モデル(Model)、回答のパーサー(Parser)を組み合わせたチェイン作成\n",
                "# StrOutputParserは回答を文字列として取得するパーサー\n",
                "chain = prompt | llm | StrOutputParser()\n",
                "\n",
                "# チェインを実行\n",
                "# 1つ目のチェインの指示に埋め込むパラメータを辞書形式で渡す\n",
                "print(chain.invoke({\n",
                "    \"language\": \"日本\",\n",
                "    \"word\": \"りんご\"\n",
                "}))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5f172c7e",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_openai import AzureChatOpenAI\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "from langchain.prompts import PromptTemplate\n",
                "\n",
                "# 1.生成AIモデルを作成\n",
                "llm = AzureChatOpenAI(\n",
                "    azure_deployment=os.environ.get(\"AZURE_OPENAI_LLM_DEPLOYMENT_MODEL\"),\n",
                "    api_version=os.environ.get(\"AZURE_OPENAI_LLM_DEPLOYMENT_API_VERSION\"),\n",
                "    temperature=0.7\n",
                ")\n",
                "\n",
                "# 2.チェインの作成\n",
                "## 要約プロンプト\n",
                "summary_prompt = PromptTemplate(\n",
                "    input_variables=[\"text\"],\n",
                "    template=\"次の単語について解説してください。: {text}\"\n",
                ")\n",
                "## 要約チェイン\n",
                "summary_chain = summary_prompt | llm | StrOutputParser()\n",
                "\n",
                "## 翻訳プロンプト\n",
                "translate_prompt = PromptTemplate(\n",
                "    input_variables=[\"text\"],\n",
                "    template=\"英語に翻訳してください。: {text}\"\n",
                ")\n",
                "\n",
                "translate_chain = translate_prompt | llm | StrOutputParser()\n",
                "\n",
                "# 3.チェインを組み合わせ\n",
                "# smmaryの結果をtranslate_chainに渡す\n",
                "chain = summary_chain | translate_chain\n",
                "\n",
                "# チェインを実行\n",
                "# 単語を解説してから英語に翻訳\n",
                "print(chain.invoke(\"大規模言語モデル\"))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f7c6a612",
            "metadata": {},
            "source": [
                "チャット(やり取り)をテンプレート化"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0b567ccb",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.prompts import (\n",
                "    HumanMessagePromptTemplate,\n",
                "    SystemMessagePromptTemplate,\n",
                "    AIMessagePromptTemplate,\n",
                "    ChatPromptTemplate\n",
                ")\n",
                "\n",
                "# ------------------------------------------------------\n",
                "# 単一のチャットをテンプレート化する\n",
                "# ------------------------------------------------------\n",
                "\n",
                "# システムプロンプトをテンプレート化\n",
                "system_template = SystemMessagePromptTemplate.from_template(\n",
                "    \"これから提示するテーマに{language}で答えてください。\")\n",
                "print(system_template.format_messages(language=\"英語\"))\n",
                "# => [HumanMessage(content=\"これから提示するテーマに英語で答えてください。\")]\n",
                "\n",
                "# 人間からの単一メッセージをテンプレート化\n",
                "human_template = HumanMessagePromptTemplate.from_template(\"本日の{theme}について\")\n",
                "print(human_template.format_messages(theme=\"天気\"))\n",
                "# => [HumanMessage(content=\"User: 今日は天気は？\")]\n",
                "\n",
                "# AIの単一メッセージをテンプレート化\n",
                "ai_template = AIMessagePromptTemplate.from_template(\n",
                "    \"本日の{theme}は{answer}となっています。\")\n",
                "print(ai_template.format_messages(theme=\"天気\", answer=\"晴れ\"))\n",
                "# => [AIMessage(content='本日の天気は晴れとなっています。')]\n",
                "\n",
                "# ------------------------------------------------------\n",
                "# 単一のチャット雛型をまとめる。\n",
                "# ------------------------------------------------------\n",
                "print(\n",
                "    ChatPromptTemplate.from_messages([\n",
                "        system_template,\n",
                "        human_template,\n",
                "        ai_template\n",
                "    ]).format_prompt(\n",
                "        language=\"英語\",\n",
                "        theme=\"天気\",\n",
                "        answer=\"晴れ\"\n",
                "    ))\n",
                "\n",
                "# ------------------------------------------------------\n",
                "# 初めからまとめて作成する\n",
                "# ------------------------------------------------------\n",
                "# 複数のチャットをまとめて定義する\n",
                "chat_template = ChatPromptTemplate.from_messages([\n",
                "    (\"system\", \"これから提示するテーマに{language}で答えてください。\"),\n",
                "    (\"human\", \"本日の{theme}について\"),\n",
                "    (\"ai\", \"本日の{theme}は{answer}となっています。\")\n",
                "])\n",
                "\n",
                "print(\n",
                "    chat_template.format_prompt(\n",
                "        language=\"英語\",\n",
                "        theme=\"天気\",\n",
                "        answer=\"晴れ\"\n",
                "    ))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7a2bcf14",
            "metadata": {},
            "source": [
                "チャットからテキスト生成を行う"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2b13ebd6",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_openai import AzureChatOpenAI\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "from langchain.prompts import ChatPromptTemplate\n",
                "\n",
                "\n",
                "# 1.生成AIモデルを作成\n",
                "llm = AzureChatOpenAI(\n",
                "    azure_deployment=os.environ.get(\"AZURE_OPENAI_LLM_DEPLOYMENT_MODEL\"),\n",
                "    api_version=os.environ.get(\"AZURE_OPENAI_LLM_DEPLOYMENT_API_VERSION\"),\n",
                "    temperature=0.7\n",
                ")\n",
                "\n",
                "# 2.チャット雛型(あるいは履歴)を作成\n",
                "chat_template = ChatPromptTemplate.from_messages([\n",
                "    (\"system\", \"{theme}に関する話題について答えてください。\"),\n",
                "    (\"human\", \"{theme}の{question}は？\"),\n",
                "    (\"ai\", \"{theme}の{question}は{answer}となります。\"),\n",
                "    (\"human\", \"{additional}\")\n",
                "])\n",
                "\n",
                "# 3.チェインを組み立て\n",
                "chain = chat_template | llm | StrOutputParser()\n",
                "\n",
                "# チェインを実行\n",
                "chain.invoke({\n",
                "    \"theme\": \"本日\",\n",
                "    \"question\": \"天気\",\n",
                "    \"answer\": \"雨\",\n",
                "    \"additional\": \"傘は必要か？\"\n",
                "})"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f531f46c",
            "metadata": {},
            "source": [
                "## 4. エージェント（Agents:LangGraph版）\n",
                "LangChain版とLangGraph版があるが、LangGraph版への移行が推奨されているためLangGraph版で解説する"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f5f39bdc",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from langchain_openai import AzureChatOpenAI\n",
                "from langgraph.prebuilt import create_react_agent\n",
                "from langchain_core.tools import tool\n",
                "# from langchain.agents import load_tools\n",
                "from datetime import datetime,date\n",
                "\n",
                "\n",
                "# 1.生成AIモデルを作成\n",
                "llm = AzureChatOpenAI(\n",
                "    azure_deployment=os.environ.get(\"AZURE_OPENAI_LLM_DEPLOYMENT_MODEL\"),\n",
                "    api_version=os.environ.get(\"AZURE_OPENAI_LLM_DEPLOYMENT_API_VERSION\"),\n",
                "    temperature=0.7\n",
                ")\n",
                "\n",
                "# 2.ツールの設定\n",
                "# Note:LangChainには便利なツールが標準でいくつか定義されている。\n",
                "# ただし、ツールによっては外部サービスのAPIキーが必要になるので調べてみてください。\n",
                "# serpapiは、Google検索をプログラムで実行してくれるAPIサービスのツールですが、APIキーの取得が必要です。\n",
                "# tools = load_tools([\"serpapi\"], llm=llm)\n",
                "\n",
                "# 自作のツールを定義する\n",
                "# RAGを構築する際は検索する部分をフレームワークを使うか自作する\n",
                "\n",
                "@tool\n",
                "def today_is():\n",
                "    \"今日の日付を返す\"\n",
                "    return  datetime.today().date()\n",
                "\n",
                "@tool\n",
                "def fetch_weather(dt:date):\n",
                "    \"指定された日付の天気を返す\"\n",
                "    today = datetime.today().date()\n",
                "    if dt < today:\n",
                "        return \"雨\"\n",
                "    elif dt == today:\n",
                "        return \"曇りのち晴れ\"\n",
                "    else:\n",
                "        return \"晴れ\"\n",
                "\n",
                "tools = [\n",
                "    today_is,\n",
                "    fetch_weather\n",
                "]\n",
                "\n",
                "# エージェントを構築する\n",
                "agent = create_react_agent(model=llm, tools=tools, prompt=\"You are a helpful assistant\")\n",
                "agent.invoke({\n",
                "    \"messages\": [{\"role\": \"user\", \"content\": \"今日の日付と天気は？\"}]\n",
                "})\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d32e144f",
            "metadata": {},
            "source": [
                "## 5. メモリ管理（LangGraph 永続化）"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fce83fb7",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langgraph.checkpoint.memory import MemorySaver\n",
                "from langchain_openai import ChatOpenAI\n",
                "from langchain.agents.react.agent import create_react_agent\n",
                "from langchain import AgentExecutor\n",
                "\n",
                "memory = MemorySaver()\n",
                "olapi = ChatOpenAI(model=\"gpt-4o-mini\")\n",
                "agent_mem = create_react_agent(\n",
                "    llm=olapi,\n",
                "    tools=[],\n",
                "    checkpointer=memory\n",
                ")\n",
                "executor_mem = AgentExecutor.from_agent_and_tools(agent=agent_mem, tools=[], verbose=True)\n",
                "\n",
                "# 会話の例\n",
                "a1 = executor_mem.invoke({\"input\": \"こんにちは\"})\n",
                "a2 = executor_mem.invoke({\"input\": \"昨日の話を覚えてる？\"})\n",
                "print(a2)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ab178830",
            "metadata": {},
            "source": [
                "## 6. ドキュメントロード & テキスト分割"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fb852699",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_community.document_loaders import PyPDFLoader\n",
                "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                "\n",
                "loader = PyPDFLoader(\"sample.pdf\")\n",
                "docs = loader.load()\n",
                "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
                "chunks = splitter.split_documents(docs)\n",
                "print(f\"チャンク数: {len(chunks)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1d260d39",
            "metadata": {},
            "source": [
                "## 7. 埋め込み & ベクターストア"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8fbff804",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_community.embeddings import OpenAIEmbeddings\n",
                "from langchain_community.vectorstores import FAISS\n",
                "\n",
                "embeddings = OpenAIEmbeddings()\n",
                "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
                "results = vectorstore.similarity_search(\"LangChain のユースケース\", k=3)\n",
                "for doc in results:\n",
                "    print(doc.page_content[:200])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e65d8336",
            "metadata": {},
            "source": [
                "## 8. 検索＋回答（Retrieval Chain）"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b2359457",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.chains import create_retrieval_chain\n",
                "\n",
                "qa_chain = create_retrieval_chain(\n",
                "    retriever=vectorstore.as_retriever(),\n",
                "    llm=llm,\n",
                "    prompt=prompt\n",
                ")\n",
                "answer = qa_chain.invoke({\"query\": \"LangChain のメモリ管理方法は？\"})\n",
                "print(answer)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "35c6d2a7",
            "metadata": {},
            "source": [
                "## 9. コールバック（ストリーミング出力）"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5f17af1d",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "handler = StreamingStdOutCallbackHandler()\n",
                "llm_stream = ChatOpenAI(streaming=True, callbacks=[handler])\n",
                "_ = llm_stream.invoke([{\"role\":\"user\",\"content\":\"最新ニュースを教えて\"}])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
