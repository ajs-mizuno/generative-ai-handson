{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a14e97bd",
   "metadata": {},
   "source": [
    "# PDFからチャンク化する事例\n",
    "セクション分けされているPDFデータを章節条にセクショニングでチャンク化したデータに変換するサンプル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c90b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PDFからテキストを抽出\n",
    "# -----------------------------------------------------------------------------\n",
    "def pdf2text(pdf_path: str) -> str:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    md_lines = []\n",
    "    for page in doc:\n",
    "        text = page.get_text(\"text\")\n",
    "        lines = text.split('\\n')\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            md_lines.append(line)\n",
    "        # ページの区切り\n",
    "        md_lines.append(\"\")\n",
    "    return '\\n'.join(md_lines)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 全角文字を半角文字で正規化\n",
    "# -----------------------------------------------------------------------------\n",
    "def normalize_text(text: str):\n",
    "    return text.translate(str.maketrans(\n",
    "        {chr(0xFF01 + i): chr(0x21 + i) for i in range(94)}\n",
    "    ))\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 文章をセクション・箇条書き単位で\n",
    "# -----------------------------------------------------------------------------\n",
    "def normalize_article(text: str):\n",
    "    # 〇箇条書きとセクションで区切り箇所を特定て置換\n",
    "    #  ※分割箇所を\"---\"で表現\n",
    "    # 正規表現にてセクション、箇条書きを特定し、---(仮)で分割\n",
    "    # ・第<数値>で始まる・・・第N章 ~~、第N節 ~~、第N条 ~~など\n",
    "    # ・<数値>.で始まる・・・ 1. ~~、2. ~~\n",
    "    # ・(数値)で始まる・・・ (1) ~~、 (2) ~~\n",
    "    text = re.sub(\n",
    "        r\"^(\\s*第\\d+.*?|\\s*\\d+\\..*|\\s*\\(\\d+\\).*)$\",\n",
    "        r\"---\\1\", text, flags=re.MULTILINE)\n",
    "\n",
    "    # 〇元データの改行を削除\n",
    "    # 元の改行は座標位置に依存するため\n",
    "    text = re.sub(r\"\\r?\\n\", \"\", text)\n",
    "\n",
    "    # 〇改行を再設定\n",
    "    # 分割箇所(\"---\")を再度改行に復元\n",
    "    text = re.sub(r\"---\", \"\\n\", text)\n",
    "    # 句点（。）で改行\n",
    "    text = re.sub(r\"。\", \"。\\n\", text)\n",
    "\n",
    "    # 一文の前後余白等を削除\n",
    "    text = \"\\n\".join(\n",
    "        line.strip() for line in text.splitlines()\n",
    "        if line.strip()\n",
    "    )\n",
    "\n",
    "    # 〇セクションに更に改行を増やして強調\n",
    "    # わかりやすくするため更に改行を追加\n",
    "    text = re.sub(\n",
    "        r\"^(第\\s*\\d+\\s*章.*)$\",\n",
    "        r\"\\n\\n\\1\", text, flags=re.MULTILINE\n",
    "    )\n",
    "    text = re.sub(\n",
    "        r\"^(第\\s*\\d+\\s*条.*)$\",\n",
    "        r\"\\n\\1\", text, flags=re.MULTILINE\n",
    "    )\n",
    "    text = re.sub(\n",
    "        r\"^(第\\s*\\d+\\s*条.*)$\",\n",
    "        r\"\\n\\1\", text, flags=re.MULTILINE\n",
    "    )\n",
    "    return text\n",
    "\n",
    "\n",
    "def chunk_articles(text: str):\n",
    "    articles = []\n",
    "    section = \"\"  # 現在の章\n",
    "    chapter = \"\"  # 現在の節\n",
    "    article = \"\"  # 現在の条\n",
    "    buffer = {\n",
    "        \"chapter\": \"\",\n",
    "        \"section\": \"\",\n",
    "        \"article\": \"\"\n",
    "    }\n",
    "\n",
    "    # バッファ\n",
    "    changed = False\n",
    "\n",
    "    # 条単位でデータを区切る\n",
    "    for line in text.splitlines():\n",
    "\n",
    "        # 書込みフラグが有効な場合、書込\n",
    "        if changed:\n",
    "            changed = False\n",
    "            if buffer[\"article\"]:\n",
    "                articles.append(buffer)\n",
    "            buffer = {\n",
    "                \"chapter\": chapter,\n",
    "                \"section\": section,\n",
    "                \"article\": article\n",
    "            }\n",
    "\n",
    "        # 〇条の場合\n",
    "        if re.match(r\"^(第\\s*\\d+\\s*条.*)$\", line):\n",
    "            changed = True\n",
    "            article = line\n",
    "\n",
    "        # 〇節の場合\n",
    "        # 現在の節を更新\n",
    "        elif re.match(r\"^(第\\s*\\d+\\s*節.*)$\", line):\n",
    "            changed = True\n",
    "            article = \"\"\n",
    "            section = line\n",
    "\n",
    "        # 〇第N章、または、付則の場合\n",
    "        # 現在の章と節を更新\n",
    "        elif re.match(r\"^(第\\s*\\d+\\s*章.*|付則.*)$\", line):\n",
    "            changed = True\n",
    "            article = \"\"\n",
    "            section = \"\"\n",
    "            chapter = line\n",
    "\n",
    "        # 区切り以外の文の場合、bufferに追記\n",
    "        elif line.strip():\n",
    "            # 区切り以外の文字は条として書き込む\n",
    "            buffer[\"article\"] = f\"{buffer[\"article\"]}{line}\\n\"\n",
    "\n",
    "    # 残りのバッファを書き込み\n",
    "    articles.append(buffer)\n",
    "\n",
    "    return articles\n",
    "\n",
    "\n",
    "def convert_pdf_to_json(input_path: str, output_path):\n",
    "    with open(output_path, mode=\"w\", encoding=\"utf8\") as f:\n",
    "        # テキスト読込\n",
    "        text = pdf2text(input_path)\n",
    "        # テキスト正規化\n",
    "        text = normalize_text(text)\n",
    "        text = normalize_article(text)\n",
    "        # チャンク化\n",
    "        articles = chunk_articles(text)\n",
    "        # データ書込み\n",
    "        f.write(json.dumps(articles, ensure_ascii=False))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    convert_pdf_to_json(input_path=\"規則.pdf\", output_path=\"就業規則.json\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
